---
layout: post
title: 多虚拟机的协同迁移
category: 虚拟化，热迁移
---

##多虚拟机的协同迁移
&emsp; 前两天读了下VEE2014上的一篇文章COMMA: Coordinating the Migration of Multi-tier Applications。多机迁移的问题在上学期跟师兄提到过，不过当时还主要是从迁移的效率上考虑，即如何在更短的时间内进行多机的迁移，想要在同一物理机上不同虚拟机之间的共享内存页上做文章。

&emsp;这篇文章主要从QoS的角度来考虑多机迁移的问题：有时候一个应用可能需要多台虚拟机来提供。文中兴趣了一个Amazon Web Service的例子，需要一台Web Server,两台App Server,以及一台DB Server共同来完成。这样，在迁移的时候，如果需要将这几台虚拟机都迁移到另外的物理机上（这四台虚拟机可能位于不同的物理机上，目的物理机也可能有多个），那么就会出现一个问题：串行的迁移各个虚拟机，还是并行的迁移虚拟机？


- 串行的迁移：有可能不能充分利用网络带宽，导致总迁移时间过长。而且如果源物理机和目的虚拟机之间的网络比较慢的话，那么只要有虚拟机迁移完成，便会造成QoS的下降，这种下降会一直持续到所有虚拟机迁移结束。
- 并行的迁移：有可能网络带宽不够用。若所有虚拟机的脏页产生速率之和大于网络带宽，那么在极端情况下，可能造成整个迁移过程永远无法完成。即使迁移完成的话，那先迁移完成的虚拟机和后迁移完成的虚拟机之间还会造成QoS的下降。

&emsp; 可见，需要一种协调机制，来动态的调整各个虚拟机的迁移时机和迁移速度。

&emsp; 文中提到的迁移与之前大多数论文中提到的迁移稍微有一点不同：在迁移的过程中，首先将虚拟机的磁盘镜像迁移到目的物理机，然后再开始物理内存页的迁移。这样做也有一定的道理：迁移完成后，如果虚拟机写磁盘的话，当然写本地磁盘会快很多。

&emsp; 文中提出的第一点就是如何合理的迁移各个虚拟机的磁盘镜像。方法很简单：根据各个镜像的不同大小占总镜像大小的比例来为其分配迁移时的带宽，这样，各个镜像便可以基本上在同时迁移完成。

&emsp; 接下来便进行物理内存页的迁移。开头讲过，串行会太慢，并行会有可能造成迁移不收敛，无法完成。那么理想的方式必然是来一个折中了：将虚拟机分组，组内并行迁移，组间串行迁移。这马上带来一个问题：根据什么进行分组？文中给出了一个方式：如果若干个虚拟机的脏页率之和小于或等于迁移时可用的带宽，那么便可以将这些虚拟机作为一组进行迁移。这就解决了并行迁移中不能收敛的问题。

&emsp; 怎么得到这些分组?文章对比了两种算法：一种相当于暴搜，把 所有组合全算出来，看哪些组合符合要求。算法的效率显然太低。不过在虚拟机数目小的情况下也可以勉强过的去。文章还用了一种启发式算法：每次从还没被分组的虚拟机中挑出两个虚拟机。其实本质就是一种贪心策略。

&emsp; 解决完了分组的问题，那么对于并行迁移还有一个问题，就是组内的虚拟机如何迁移。对于组内的不同虚拟机，虽然其脏页率之和小于可用带宽，可以“放心”的进行并行迁移。但是由于各个虚拟机的内存大小不同，如果同时开始迁移，可能会造成结束时间不同，那么这那段时间内QoS会下降。有人可能说，那像迁移硬盘镜像那样根据大小去分配带宽不就完了嘛？可是这又会有一个问题，就是如果按比例来分配的话，有可能某台虚拟机分配到的带宽会小于这台虚拟机的脏页率。这就会造成这台虚拟机无法结束迁移，这时，唯一的办法就是，对这台虚拟机内部实行“限流”。这显然对于提供Service的机器来讲是不愿意接受的。

&emsp; 这时，情景就变成了，同时开始会造成可能会不同时结束，同时开始同时结束会造成虚拟机性能下降，那么，答案就比较明显了：不同时开始，同时结束不就好了。文章中确实就是这么做的：根据产生脏页的速率，让一部分脏页比较多的虚拟机先开始迁移，脏页少的虚拟机后迁移。不同时开始，尽量做到同时结束。

&emsp; 最后剩下的问题就是：如何去动态的预测某台虚拟机的脏页率。其方法在作者的一篇期刊文章里进行了详细的讲述，等读完了再记录一下。

&emsp; 最后就是性能测试和数据分析了。在实验室和Amazon EC2的真实场景下进行了测试，都达到了很好的效果。

---








