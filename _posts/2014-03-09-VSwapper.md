---
layout: post
title: 虚拟机与物理机内存的协同管理
category: 虚拟化，内存管理
---
##VSwapper: A Memory Swapper for Virtualized Environment
&emsp; ASPLOS14上找到了一篇和虚拟化场景下内存管理相关的论文，比较感兴趣，花了一天的时间读了下。

&emsp; 虚拟化的背景自不必说。如果一个物理机上的虚拟机数目多起来以后，物理机的内存便会吃不消，导致内存"overcommit"，这时，物理机就会把部分页换出到硬盘上（当然也有可能把一部分虚拟机迁移到其它物理机上）。由于QEMU/KVM虚拟机其实就相当于物理中一个进程，而这个QEMU申请内存时是从用户态用malloc分配的（查了下kvm的官网，上面的原话是 “If a guest is going to have 1GB of physical memory, qemu/kvm will effectively do a malloc(1<<30), allocating 1GB of host virtual space.。”)。可见，对于一个KVM虚拟机，它的所有内存页在物理机看来，都是匿名页。这时问题就来了：

- 当物理机内存overcommit时，会释放内存，释放的办法有两种：对于file backed页，如果页是clean的，可能直接将其释放掉，如果页是dirty的，将其与磁盘同步，然后释放。对于匿名页，将其写入交换区。由于KVM虚拟机的所有页都是匿名页，那么，这些页在物理机需要释放时自然会被写入交换区。这就造成了不匹配的现象：KVM虚拟机里虽然所有页都是匿名页，但有一部分其实是有file backed的，比如来自虚拟机磁盘镜像的那些页。这些页如果其中有clean的，那么再写入交换区完全是浪费的。
- 当虚拟机决定将内存页a的内容完全复制到页b时，若页b恰巧被物理机换出了，那么需要从物理机的swap分区中将页b读入，然后再将页a的内容复制给页b。如果是整页的复制，或者是初始化页b，那么有可能以前页b中的旧内容根本不会被用到，这时从物理机的swap中读入页b其实根本没必要。
- 在读文件时，物理机有预读机制，虚拟机也有。当物理机内存紧缺时，虚拟机并不会感知到。如果这时虚拟机还在一个劲的预读，那么读进来的这些页随后会被物理机换出到swap分区中。这样，就相当于虚拟机所需要的页从其虚拟磁盘上移动到了物理机的swap分区中。这有一个不好：本来这些页在虚拟磁盘上是连续存放的，这样一挪，到swap中就可能不连续了，因此再swap进来的时候可能预读起的效果就不如以前大了（这一点我感觉多少有点牵强，要知道swap的时候也是成块分配swap slot的，当然要是swap太多了找不到连续的swap slot也有可能）。

&emsp; 另外说了一些小点，感觉有点扯，就不分析了。后面是解决方案：

- 在读虚拟磁盘时，QEMU用的是read库函数（文章说是standard system call，这不准确)，现在他们将read改为mmap。这样就不一样了：sys_read系统调用会将文件内容存入到与文件对应的page cache，然后将page cache里的内容复制一份到user space。而sys_mmap的流程是，将文件内容读入到page cache，然后做一个映射，直接将用户地址空间映射到page cache上，这样就少了一层内核空间到用户空间的复制。同时，用户空间的这些页也变成了file backed。这样在换出的时候，物理机自然就会考虑页是clean还是为dirty了。
- 在上述修改页b的场景中，虚拟机操作页b时会产生一个缺页异常，现在修改这个缺页异常的handler：人工来模拟对页b的写。即另外申请一个缓冲区（一页大小），将写的东西先放到那个缓冲区里。如果发现最后缓冲区这一页都被写了（中间没有插入读操作)，那证明从swap中读b是肯定没用的了,于是直接认为缓冲区这一页就是b，把页面映射一改。如果写中间插入读操作了，那没办法，只好乖乖去读，读进来之后把当前的缓冲区和旧的页b作一个合并。

&emsp; 很有意思的是，在作者给出的性能测试中，有好多场景该方案性能都是下降的。。。
但是在虚拟机work set比较不稳定的情况下，效果不错（work set不稳定是通过每隔10s开/关一下benchmark实现的)

